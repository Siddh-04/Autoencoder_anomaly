{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder for Anomaly Detection in CERN Data\n",
    "\n",
    "This notebook demonstrates the complete workflow for training an autoencoder on Standard Model (SM) data and detecting Beyond Standard Model (BSM) anomalies.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- **Training**: Autoencoder learns to reconstruct SM (background) data\n",
    "- **Detection**: High reconstruction error indicates BSM (signal) anomalies\n",
    "- **Application**: Search for bulk graviton signals in particle physics data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from model import create_autoencoder, reconstruction_error\n",
    "from data_utils import DataProcessor, generate_synthetic_data\n",
    "from train import train_autoencoder\n",
    "from evaluate import evaluate_anomaly_detection\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"Input dimension: {config['model']['input_dim']}\")\n",
    "print(f\"Encoding dimensions: {config['model']['encoding_dims']}\")\n",
    "print(f\"Latent dimension: {config['model']['latent_dim']}\")\n",
    "print(f\"Batch size: {config['training']['batch_size']}\")\n",
    "print(f\"Epochs: {config['training']['epochs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate/Load Data\n",
    "\n",
    "For demonstration purposes, we'll generate synthetic data. In practice, replace this with your actual CERN data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "sm_data, bsm_data = generate_synthetic_data(\n",
    "    n_samples=10000,\n",
    "    n_features=config['model']['input_dim'],\n",
    "    anomaly_ratio=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"SM data shape: {sm_data.shape}\")\n",
    "print(f\"BSM data shape: {bsm_data.shape}\")\n",
    "\n",
    "# Visualize data distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].hist(sm_data[:, 0], bins=50, alpha=0.7, label='SM', color='blue')\n",
    "axes[0].hist(bsm_data[:, 0], bins=50, alpha=0.7, label='BSM', color='red')\n",
    "axes[0].set_xlabel('Feature 0')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Feature Distribution: SM vs BSM')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(np.mean(sm_data, axis=1), bins=50, alpha=0.7, label='SM', color='blue')\n",
    "axes[1].hist(np.mean(bsm_data, axis=1), bins=50, alpha=0.7, label='BSM', color='red')\n",
    "axes[1].set_xlabel('Mean of all features')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Mean Feature Distribution')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Autoencoder\n",
    "\n",
    "Train the autoencoder on SM data only (normal/background data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model, history = train_autoencoder(config, use_synthetic=True)\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history.history['loss'], label='Training Loss')\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss (MSE)')\n",
    "axes[0].set_title('Training Progress: Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# MAE\n",
    "axes[1].plot(history.history['mae'], label='Training MAE')\n",
    "axes[1].plot(history.history['val_mae'], label='Validation MAE')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].set_title('Training Progress: MAE')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Anomaly Detection\n",
    "\n",
    "Test the model's ability to detect BSM anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate anomaly detection\n",
    "metrics = evaluate_anomaly_detection(config, use_synthetic=True)\n",
    "\n",
    "print(\"\\nEvaluation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Latent Space\n",
    "\n",
    "Explore the learned latent representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "data_processor = DataProcessor(config)\n",
    "sm_sample = data_processor.preprocess_data(sm_data[:1000], fit_scaler=True)\n",
    "bsm_sample = data_processor.preprocess_data(bsm_data[:100], fit_scaler=False)\n",
    "\n",
    "# Encode data\n",
    "sm_encoded = model.encode(sm_sample).numpy()\n",
    "bsm_encoded = model.encode(bsm_sample).numpy()\n",
    "\n",
    "# Visualize (first 2 dimensions)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(sm_encoded[:, 0], sm_encoded[:, 1], \n",
    "           alpha=0.5, label='SM', c='blue', s=30)\n",
    "plt.scatter(bsm_encoded[:, 0], bsm_encoded[:, 1], \n",
    "           alpha=0.7, label='BSM', c='red', s=30)\n",
    "plt.xlabel('Latent Dimension 1')\n",
    "plt.ylabel('Latent Dimension 2')\n",
    "plt.title('Latent Space Representation')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Example Reconstructions\n",
    "\n",
    "Visualize actual vs reconstructed samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select samples\n",
    "sm_samples = sm_sample[:5]\n",
    "bsm_samples = bsm_sample[:5]\n",
    "\n",
    "# Get reconstructions\n",
    "sm_reconstructed = model.predict(sm_samples)\n",
    "bsm_reconstructed = model.predict(bsm_samples)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "\n",
    "for i in range(5):\n",
    "    # SM samples\n",
    "    axes[0, i].plot(sm_samples[i], label='Original', alpha=0.7)\n",
    "    axes[0, i].plot(sm_reconstructed[i], label='Reconstructed', alpha=0.7)\n",
    "    axes[0, i].set_title(f'SM Sample {i+1}')\n",
    "    axes[0, i].legend()\n",
    "    axes[0, i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # BSM samples\n",
    "    axes[1, i].plot(bsm_samples[i], label='Original', alpha=0.7)\n",
    "    axes[1, i].plot(bsm_reconstructed[i], label='Reconstructed', alpha=0.7)\n",
    "    axes[1, i].set_title(f'BSM Sample {i+1}')\n",
    "    axes[1, i].legend()\n",
    "    axes[1, i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "The autoencoder successfully:\n",
    "1. Learns to reconstruct SM (background) data with low error\n",
    "2. Produces high reconstruction error for BSM (signal) data\n",
    "3. Enables anomaly detection by thresholding reconstruction error\n",
    "\n",
    "### Next Steps:\n",
    "- Replace synthetic data with actual CERN particle physics data\n",
    "- Tune hyperparameters for optimal performance\n",
    "- Experiment with different architectures (VAE, convolutional layers, etc.)\n",
    "- Apply to bulk graviton signal detection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
